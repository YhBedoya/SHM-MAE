{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhbedoya/VirtualEnvs/SHMmae_venv/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "import argparse\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/yhbedoya/Repositories/SHM-MAE\")\n",
    "import models_audio_mae_R\n",
    "import glob\n",
    "pd.options.mode.chained_assignment = None\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(chkpt_dir, arch='audioMae_vit_base'):\n",
    "    # build model\n",
    "    model = getattr(models_audio_mae_R, arch)()\n",
    "    # load model\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def run_one_image(frequencies, times, spectrogram, model, test):\n",
    "def run_one_image(spectrogram, model, test):\n",
    "    gnr_max = -3.3793421008937514\n",
    "    gnr_min = -24.496400092774163\n",
    "\n",
    "    #x = torch.transpose(spectrogram, 1, 2) #shape [1,80,100]\n",
    "    x = torch.tensor(spectrogram)\n",
    "    #MIN MAX SCALER\n",
    "    #x = (x -gnr_min) /(gnr_max-gnr_min) \n",
    "\n",
    "    # make it a batch-like\n",
    "    x = x.unsqueeze(dim=0)\n",
    "\n",
    "    y = model(x.float(), mask_ratio=0.8)\n",
    "\n",
    "    return y\n",
    "\n",
    "    # run MAE\n",
    "    loss, y, mask = model(x.float(), mask_ratio=0.8)\n",
    "    #y = model_mae.unpatchify(y).detach().cpu()\n",
    "    y = y.type(torch.float64)\n",
    "    y = model.unpatchify(y).detach().cpu()\n",
    "    \n",
    "    y = torch.transpose(torch.squeeze(torch.squeeze(input=y)),0,1)\n",
    "\n",
    "\n",
    "    #y = torch.squeeze(torch.squeeze(input=out))\n",
    "    y = y * (gnr_max-gnr_min) \n",
    "    y = y + gnr_min\n",
    "\n",
    "    # visualize the mask\n",
    "    mask = mask.detach()\n",
    "    mask = mask.unsqueeze(-1).repeat(1, 1, model.patch_embed.patch_size[0]**2)  # (N, H*W, p*p*3)\n",
    "    mask = model.unpatchify(mask)  # 1 is removing, 0 is keeping\n",
    "    #mask = torch.einsum('nchw->nhwc', mask).detach().cpu()\n",
    "    \n",
    "    mask = torch.transpose(torch.squeeze(torch.squeeze(input=mask)),0,1)\n",
    "    #print(f'mask shape {mask.shape}')\n",
    "    #x = torch.einsum('nchw->nhwc', x)\n",
    "  \n",
    "\n",
    "    # masked image\n",
    "    spectrogram = torch.squeeze(spectrogram)\n",
    "    #print(f'spectrogram shape {spectrogram.shape}')\n",
    "    im_masked = spectrogram * (1 - mask)\n",
    "    #print(f'inmask shape {im_masked.shape}')\n",
    "\n",
    "    # MAE reconstruction pasted with visible patches\n",
    "    im_paste = spectrogram * (1 - mask) + y * mask\n",
    "    #im_paste2 = spectrogram * (1 - mask) + ((y + torch.abs(0.6*torch.min(y))) * mask)\n",
    "    #print(f'im_paste shape {im_paste.shape}')\n",
    "\n",
    "    #diff reconstruction original\n",
    "    diff = torch.abs(spectrogram - im_paste)\n",
    "\n",
    "    mse = (np.square(spectrogram - im_paste)).mean()\n",
    "\n",
    "    if test:\n",
    "      return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHMDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, isPreTrain, isFineTuning, isEvaluation):\n",
    "        if isPreTrain:\n",
    "            self.start_time, self.end_time = \"05/12/2021 00:00\", \"05/12/2021 23:59\"\n",
    "            self.datasetSize = 500000\n",
    "        elif isFineTuning:\n",
    "            self.start_time, self.end_time = \"06/12/2021 00:00\", \"06/12/2021 05:59\"\n",
    "            self.datasetSize = 200000\n",
    "        elif isEvaluation:\n",
    "            self.start_time, self.end_time = \"06/12/2021 06:00\", \"06/12/2021 11:59\"\n",
    "            self.datasetSize = 50000\n",
    "        else:\n",
    "            self.start_time, self.end_time = \"06/12/2021 23:00\", \"06/12/2021 23:59\"\n",
    "            self.datasetSize = 50000\n",
    "        self.path = data_path #'/home/yhbedoya/Repositories/SHM-MAE/traffic/20211205/'\n",
    "        self.noisySensors = [\"C12.1.4\", \"C17.1.2\"]\n",
    "        self.minDuration = 0.25\n",
    "        self.data = self._readCSV()\n",
    "        self.distanceToSensor = self._readDistanceToSensor()\n",
    "        self.sensorVarDict = self._calculateThresholds(isPreTrain=isPreTrain)\n",
    "        self.pesaDataDf = self._readLabels()\n",
    "        self.labelsDf, self.groupsDf = self._labelAssignment()\n",
    "        self.sampleRate = 100\n",
    "        self.frameLength = 198\n",
    "        self.stepLength = 58\n",
    "        self.windowLength= 5990\n",
    "        self.windowStep = 1500\n",
    "        self.data, self.limits, self.totalWindows, min, max = self._partitioner()\n",
    "        if isPreTrain:\n",
    "            self.min = min\n",
    "            self.max = max\n",
    "        else:\n",
    "            self.min = -24.496400092774163\n",
    "            self.max = -3.3793421008937514\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.totalWindows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start, end, label, timeSlice, sensor = self.limits[index]\n",
    "        slice = self.data[start:end]\n",
    "        frequencies, times, spectrogram = self._transformation(slice)\n",
    "        spectrogram = torch.unsqueeze(torch.tensor(spectrogram, dtype=torch.float64), 0)\n",
    "        NormSpect = self._normalizer(spectrogram).type(torch.float16)\n",
    "        #print(f'type {type(NormSpect)}, inp shape: {slice.shape} out shape: {NormSpect.shape}')\n",
    "        return torch.transpose(NormSpect, 1, 2), label\n",
    "\n",
    "    def _readCSV(self):\n",
    "        print(f'reading CSV files')\n",
    "        start = datetime.strptime(self.start_time, '%d/%m/%Y %H:%M')\n",
    "        end = datetime.strptime(self.end_time, '%d/%m/%Y %H:%M')\n",
    "\n",
    "        ldf = list()\n",
    "        for p in tqdm(glob.glob(self.path + \"*.csv\")):\n",
    "            name = os.path.split(p)[-1]\n",
    "            nstr = datetime.strptime(name, 'traffic_%Y%m%dH%H%M%S.csv')\n",
    "            if start <= nstr < end:\n",
    "                df_tmp = pd.read_csv(p)\n",
    "                c_drop = set(df_tmp.columns) - set([\"sens_pos\", \"z\", \"ts\"])\n",
    "                if len(c_drop) > 0:\n",
    "                    df_tmp.drop(columns=list(c_drop), inplace=True)\n",
    "                ldf.append(df_tmp)\n",
    "        df = pd.concat(ldf).sort_values(by=['sens_pos', 'ts'])\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        #df = df[df['sens_pos'].isin(self.sensors)]\n",
    "        df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "        df['Time'] = df['ts'].dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "        df[\"zN\"] = df[\"z\"]-np.mean(df[\"z\"])\n",
    "        df[\"vars\"] = df[\"zN\"].rolling(window=100).var().fillna(0)\n",
    "        df[\"vars\"] = df[\"vars\"].rolling(window=100).mean().fillna(0)\n",
    "        print(f'finish reading process')\n",
    "        return df\n",
    "\n",
    "    def _readDistanceToSensor(self):\n",
    "        distanceToSensor = {}\n",
    "        with open('/home/yhbedoya/Repositories/SHM-MAE/LabelGeneration/distanceToSensor.csv') as f: #/home/yvelez/sacertis/distanceToSensor.csv\n",
    "            for line in f.readlines():\n",
    "                sensor, distance = line.replace(\"'\", \"\").replace(\"\\n\",\"\").split(\",\")\n",
    "                distanceToSensor[sensor] = float(distance)\n",
    "        return distanceToSensor\n",
    "\n",
    "    def _readLabels(self):\n",
    "        start_time = datetime.strptime(self.start_time, '%d/%m/%Y %H:%M')\n",
    "        end_time = datetime.strptime(self.end_time, '%d/%m/%Y %H:%M')\n",
    "        pesaDataDf = pd.read_csv(\"/home/yhbedoya/Repositories/SHM-MAE/dati_pese_dinamiche/dati 2021-12-04_2021-12-12 pesa km 104,450.csv\", sep=\";\", index_col=0)\n",
    "        pesaDataDf = pesaDataDf[[\"Id\", \"StartTimeStr\", \"ClassId\", \"GrossWeight\", \"Velocity\", \"VelocityUnit\"]]\n",
    "        pesaDataDf[\"Time\"] = pd.to_datetime(pesaDataDf[\"StartTimeStr\"])\n",
    "        pesaDataDf[\"Time\"] = pesaDataDf[\"Time\"].dt.strftime('%Y-%d-%m %H:%M:00')\n",
    "        pesaDataDf[\"Time\"] = pd.to_datetime(pesaDataDf[\"Time\"]) + pd.to_timedelta(-1,'H')\n",
    "        pesaDataDf.sort_values(by=\"Id\", inplace=True)\n",
    "        pesaDataDf = pesaDataDf[(pesaDataDf[\"Time\"]>=start_time) & (pesaDataDf[\"Time\"]<=end_time)]\n",
    "        pesaDataDf.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return pesaDataDf\n",
    "\n",
    "    def groupsGenerator(self, sensorData, minTime, maxTime, threshold):\n",
    "        slice = sensorData[(sensorData[\"ts\"]>= minTime) & (sensorData[\"ts\"]<= maxTime)]\n",
    "        \n",
    "        slice[\"outlier\"] = slice[\"vars\"].apply(lambda x: x>=threshold)\n",
    "        outliers = slice[slice[\"outlier\"] == True].reset_index().to_dict(\"records\")\n",
    "\n",
    "        if len(outliers) == 0:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        last = minTime\n",
    "        timeStart = outliers[0][\"ts\"]\n",
    "        flag = True\n",
    "        groups = []\n",
    "        groupTimes = []\n",
    "        groupIndexes = []\n",
    "        groupVars = []\n",
    "        label = np.nan\n",
    "        groupId = 0\n",
    "        for outlier in outliers:\n",
    "            if ((outlier[\"ts\"] - last).total_seconds() < 2) or flag:\n",
    "                groupTimes.append(outlier[\"ts\"])\n",
    "                groupVars.append(outlier[\"vars\"])\n",
    "                flag = False\n",
    "                timeEnd = outlier[\"ts\"]\n",
    "            else:\n",
    "                start, end = min(groupTimes), max(groupTimes)\n",
    "                groupSignal = sensorData[(sensorData[\"ts\"]>= start) & (sensorData[\"ts\"]<= end)][\"zN\"]\n",
    "                signalPower = np.sqrt(np.mean(np.array(groupSignal)**2))**2 \n",
    "                pointMaxVar = groupTimes[np.argmax(groupVars)]\n",
    "                if ((end - start).total_seconds() > self.minDuration):\n",
    "                    label = {\"groupId\": groupId,\"start\": start, \"end\": end, \"signalPower\": signalPower, \n",
    "                    \"pointMaxVar\": pointMaxVar}\n",
    "                    groups.append(label)\n",
    "                groupId += 1\n",
    "                groupTimes = [outlier[\"ts\"],]\n",
    "                groupVars = [outlier[\"vars\"],]\n",
    "            last = outlier[\"ts\"]\n",
    "\n",
    "        start, end = min(groupTimes), max(groupTimes)\n",
    "        groupSignal = sensorData[(sensorData[\"ts\"]>= start) & (sensorData[\"ts\"]<= end)][\"zN\"]\n",
    "        signalPower = np.sqrt(np.mean(np.array(groupSignal)**2))**2 \n",
    "        pointMaxVar = groupTimes[np.argmax(groupVars)]\n",
    "        if ((end-start).total_seconds() > self.minDuration):\n",
    "            label = {\"groupId\": groupId,\"start\": start, \"end\": end, \"signalPower\": signalPower, \n",
    "            \"pointMaxVar\": pointMaxVar}\n",
    "            groups.append(label)\n",
    "\n",
    "        if len(groups)>0:\n",
    "            groupsDf = pd.DataFrame(groups).sort_values(\"signalPower\", ascending=False)\n",
    "        else:\n",
    "            groupsDf = pd.DataFrame()\n",
    "\n",
    "        return groupsDf\n",
    "\n",
    "    def _labelAssignment(self,):\n",
    "        sensorLabelsDfList = []\n",
    "        groupsDfList = []\n",
    "\n",
    "        sensorsList = self.data[\"sens_pos\"].unique()\n",
    "        for sensor in sensorsList:\n",
    "            if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()) or (sensor not in self.sensorVarDict.keys()):\n",
    "                continue\n",
    "            assignedLabels = {}\n",
    "            assignedLabels2 = {}\n",
    "            sensorLabelsDf = self.pesaDataDf.copy(deep=True)\n",
    "            sensorLabelsDf[\"EstimatedTime\"] = sensorLabelsDf[\"Time\"] + pd.to_timedelta((float(self.distanceToSensor[sensor])/(sensorLabelsDf[\"Velocity\"]/3.6))-20,'S')\n",
    "            sensorLabelsDf[\"MaxTime\"] = sensorLabelsDf[\"EstimatedTime\"] + pd.to_timedelta(120,'S')\n",
    "            minTime = sensorLabelsDf[\"EstimatedTime\"].min()\n",
    "            maxTime = sensorLabelsDf[\"MaxTime\"].max()\n",
    "            sensorLabelsDf.sort_values(\"GrossWeight\", inplace=True, ascending=False)\n",
    "\n",
    "            sensorData = self.data[self.data[\"sens_pos\"]==sensor]\n",
    "            threshold = self.sensorVarDict[sensor][\"threshold\"]\n",
    "\n",
    "            groupsDf = self.groupsGenerator(sensorData, minTime, maxTime, threshold)\n",
    "            print(f\"Total groups found for sensor {sensor}: {groupsDf.shape[0]}\")\n",
    "            if groupsDf.empty:\n",
    "                continue\n",
    "\n",
    "            availableGroupsDf = groupsDf.copy(deep=True)\n",
    "            for index, row in sensorLabelsDf.iterrows():\n",
    "                if row[\"Id\"] in assignedLabels:\n",
    "                    continue\n",
    "                \n",
    "                if availableGroupsDf.empty:\n",
    "                    break\n",
    "\n",
    "                candidatesDf = availableGroupsDf[(row[\"EstimatedTime\"] <= availableGroupsDf[\"pointMaxVar\"]) & (availableGroupsDf[\"pointMaxVar\"] <= row[\"MaxTime\"])]\n",
    "                if not candidatesDf.empty:\n",
    "                    assignedLabels[row[\"Id\"]] = candidatesDf.iloc[0].to_dict()\n",
    "                    assignedLabels2[candidatesDf.iloc[0][\"groupId\"]] = row[\"Id\"]\n",
    "                    availableGroupsDf.drop(candidatesDf.index[0], inplace=True)\n",
    "            \n",
    "            sensorLabelsDf[\"sens_pos\"] = sensor\n",
    "            sensorLabelsDf[\"labels\"] = sensorLabelsDf.apply(lambda row: assignedLabels[row[\"Id\"]] if row[\"Id\"] in assignedLabels else np.nan, axis=1)\n",
    "            sensorLabelsDf.sort_values(\"Id\", inplace=True)\n",
    "            groupsDf[\"sens_pos\"] = sensor\n",
    "            groupsDf[\"labels\"] = groupsDf.apply(lambda row: assignedLabels2[row[\"groupId\"]] if row[\"groupId\"] in assignedLabels2 else np.nan, axis=1)\n",
    "            groupsDf.sort_values(\"groupId\", inplace=True)\n",
    "            groupsDf.dropna(inplace=True)\n",
    "\n",
    "            sensorLabelsDfList.append(sensorLabelsDf)\n",
    "            groupsDfList.append(groupsDf)\n",
    "\n",
    "        labelsDf = pd.concat(sensorLabelsDfList)\n",
    "        groupsDf =  pd.concat(groupsDfList)\n",
    "\n",
    "        print(f\"Total labels: {len(labelsDf)}\")\n",
    "        totnan = labelsDf[\"labels\"].isna().sum()\n",
    "        print(f\"Total nan labels: {totnan}\")\n",
    "        print(f\"Proportion of match labels: {1-(totnan/len(labelsDf))}\")\n",
    "\n",
    "        return labelsDf, groupsDf\n",
    "\n",
    "    def _labelAssigner(self, timeSlice, sensor):\n",
    "        start, end = timeSlice.min(), timeSlice.max()\n",
    "        vehiclesInSliceDf = self.groupsDf[(self.groupsDf[\"pointMaxVar\"]>=start) &\n",
    "        (self.groupsDf[\"pointMaxVar\"]<=end) &\n",
    "        (self.groupsDf[\"sens_pos\"]==sensor)]\n",
    "        return vehiclesInSliceDf.shape[0]\n",
    "\n",
    "    def _partitioner(self):\n",
    "        sensors = self.data['sens_pos'].unique().tolist()\n",
    "        print(f'start partitioner')\n",
    "        partitions = {}\n",
    "        cumulatedWindows = 0\n",
    "        limits = dict()\n",
    "        print(f'Generating windows')\n",
    "        for sensor in tqdm(sensors):\n",
    "            if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()):\n",
    "                continue\n",
    "            sensorData = self.data[self.data['sens_pos']==sensor]\n",
    "            totalFrames = sensorData.shape[0]\n",
    "            totalWindows = math.ceil((totalFrames-self.windowLength)/self.windowStep)\n",
    "            start = cumulatedWindows\n",
    "            cumulatedWindows += totalWindows\n",
    "            end = cumulatedWindows\n",
    "            indexStart = sensorData.index[0]\n",
    "            partitions[sensor]= (start, end, indexStart)\n",
    "\n",
    "        timeData = torch.tensor(self.data[\"z\"].values, dtype=torch.float64)\n",
    "        timestamps = self.data[\"ts\"]\n",
    "        cummulator = -1\n",
    "\n",
    "        mins = list()\n",
    "        maxs = list()\n",
    "        print(f'Defining useful windows limits')\n",
    "        indexes = list(range(0, cumulatedWindows))\n",
    "        random.shuffle(indexes)\n",
    "\n",
    "        for index in tqdm(indexes):\n",
    "            if cummulator >= self.datasetSize:\n",
    "                break\n",
    "            for sensor,v in partitions.items():\n",
    "                if index in range(v[0], v[1]):\n",
    "                    start = v[2]+(index-v[0])*self.windowStep\n",
    "                    timeSlice = timestamps[start: start+self.windowLength]\n",
    "                    label = self._labelAssigner(timeSlice, sensor)\n",
    "                    filteredSlice = timeData[start: start+self.windowLength]\n",
    "                    signalPower = self.power(filteredSlice)\n",
    "\n",
    "                    if (signalPower>1.25*10**-6) or (label>0):\n",
    "                        cummulator += 1\n",
    "                        limits[cummulator] = (start, start+self.windowLength, label, timeSlice, sensor)\n",
    "                        slice = timeData[start:start+self.windowLength]\n",
    "                        frequencies, times, spectrogram = self._transformation(torch.tensor(slice, dtype=torch.float64))\n",
    "                        mins.append(np.min(np.array(spectrogram)))\n",
    "                        maxs.append(np.max(np.array(spectrogram)))\n",
    "                    break\n",
    "        print(f'Total windows in dataset: {cummulator}')\n",
    "        min = np.min(np.array(mins))\n",
    "        max = np.max(np.array(maxs))   \n",
    "        print(f'General min: {min}')\n",
    "        print(f'General max: {max}')\n",
    "        return timeData, limits, cummulator, min, max\n",
    "\n",
    "    def _transformation(self, slice):\n",
    "        sliceN = slice-torch.mean(slice)\n",
    "        frequencies, times, spectrogram = signal.spectrogram(sliceN,self.sampleRate,nfft=self.frameLength,noverlap=(self.frameLength - self.stepLength), nperseg=self.frameLength,mode='psd')\n",
    "\n",
    "        return frequencies, times, np.log10(spectrogram)\n",
    "    \n",
    "    def _normalizer(self, spectrogram):\n",
    "        spectrogramNorm = (spectrogram - self.min) / (self.max - self.min)\n",
    "        return spectrogramNorm\n",
    "\n",
    "    def power(self, slice):\n",
    "        return np.sqrt(np.mean(np.array(slice)**2))**2\n",
    "\n",
    "    def interquartileRule(self, data):\n",
    "        # Calculate the first quartile (Q1)\n",
    "        Q1 = np.percentile(data, 25)\n",
    "\n",
    "        # Calculate the third quartile (Q3)\n",
    "        Q3 = np.percentile(data, 75)\n",
    "\n",
    "        # Calculate the interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the upper and lower bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    def _calculateThresholds(self, isPreTrain):\n",
    "        if isPreTrain:\n",
    "            print(f'Start creating thresholds')\n",
    "            varDf = self.data[[\"sens_pos\", \"vars\"]]\n",
    "            sensorsList = self.data[\"sens_pos\"].unique()\n",
    "            sensorVarDict = {}\n",
    "            for sensor in tqdm(sensorsList):\n",
    "                if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()):\n",
    "                    continue\n",
    "                sensorVarDf = varDf[varDf[\"sens_pos\"]==sensor]\n",
    "                lower_bound, upper_bound = self.interquartileRule(sensorVarDf[\"vars\"])\n",
    "                sensorVarDf = sensorVarDf[(sensorVarDf[\"vars\"]>lower_bound) & (sensorVarDf[\"vars\"]<upper_bound)]\n",
    "                mean = sensorVarDf[\"vars\"].mean()\n",
    "                std = sensorVarDf[\"vars\"].std()\n",
    "                threshold = mean + 3.5 * std\n",
    "                sensorVarDict[sensor] = {\"mean\": mean, \"std\": std, \"threshold\": threshold}\n",
    "                #with open(\"/content/drive/MyDrive/Data Science and Engineering - PoliTo2/Thesis/models/MAE-SHM/output_dir_TE/sensorVarDict.json\", \"w\") as f:\n",
    "                #    # Write the dict to the file\n",
    "                #    json.dump(sensorVarDict, f)\n",
    "            print(f'Finish thresholds creation')\n",
    "        else:\n",
    "            print(f'Start reading thresholds')\n",
    "            with open(\"/home/yhbedoya/Repositories/SHM-MAE/TrafficEstimation/sensorVarDict.json\", \"r\") as f:\n",
    "                # Load the dict from the file\n",
    "                sensorVarDict = json.load(f)\n",
    "\n",
    "            print(f'Finish thresholds reading')\n",
    "\n",
    "        return sensorVarDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/home/yhbedoya/Repositories/SHM-MAE/TrafficEstimation/fineTuning/checkpoint-199.pth'\n",
    "model_mae = prepare_model(chkpt_dir, 'audioMae_vit_base_R')\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:10<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n",
      "Start reading thresholds\n",
      "Finish thresholds reading\n",
      "Total groups found for sensor C1.1.1: 45\n",
      "Total groups found for sensor C1.1.2: 24\n",
      "Total groups found for sensor C1.1.3: 92\n",
      "Total groups found for sensor C1.2.1: 25\n",
      "Total groups found for sensor C1.2.2: 27\n",
      "Total groups found for sensor C1.2.3: 29\n",
      "Total groups found for sensor C2.1.2: 21\n",
      "Total groups found for sensor C2.1.3: 26\n",
      "Total groups found for sensor C2.1.4: 18\n",
      "Total groups found for sensor C2.2.2: 21\n",
      "Total groups found for sensor C2.2.3: 23\n",
      "Total groups found for sensor C2.2.4: 16\n",
      "Total groups found for sensor C3.1.2: 27\n",
      "Total groups found for sensor C3.1.3: 39\n",
      "Total groups found for sensor C3.1.4: 24\n",
      "Total groups found for sensor C3.2.2: 20\n",
      "Total groups found for sensor C3.2.3: 22\n",
      "Total groups found for sensor C3.2.4: 18\n",
      "Total groups found for sensor C4.1.2: 20\n",
      "Total groups found for sensor C4.1.3: 53\n",
      "Total groups found for sensor C4.1.4: 23\n",
      "Total groups found for sensor C4.2.2: 19\n",
      "Total groups found for sensor C4.2.3: 21\n",
      "Total groups found for sensor C4.2.4: 17\n",
      "Total groups found for sensor C5.1.2: 18\n",
      "Total groups found for sensor C5.1.3: 22\n",
      "Total groups found for sensor C5.1.4: 23\n",
      "Total groups found for sensor C5.2.2: 22\n",
      "Total groups found for sensor C5.2.3: 19\n",
      "Total groups found for sensor C5.2.4: 43\n",
      "Total groups found for sensor C6.1.2: 23\n",
      "Total groups found for sensor C6.1.3: 12\n",
      "Total groups found for sensor C6.1.4: 23\n",
      "Total groups found for sensor C6.2.2: 19\n",
      "Total groups found for sensor C6.2.3: 23\n",
      "Total groups found for sensor C6.2.4: 32\n",
      "Total labels: 972\n",
      "Total nan labels: 216\n",
      "Proportion of match labels: 0.7777777777777778\n",
      "start partitioner\n",
      "Generating windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [00:24<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining useful windows limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8316 [00:00<?, ?it/s]/home/yhbedoya/VirtualEnvs/SHMmae_venv/lib/python3.7/site-packages/ipykernel_launcher.py:263: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 8316/8316 [00:12<00:00, 675.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in dataset: 2327\n",
      "General min: -19.50025714635237\n",
      "General max: -3.661140550429458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/yhbedoya/Repositories/SHM-MAE/traffic/20211206/\"\n",
    "InsistDataset = SHMDataset(data_path= data_path, \n",
    "isPreTrain=False, isFineTuning=False, isEvaluation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexList = []\n",
    "for index in range(2327):\n",
    "   label = InsistDataset[index][1]\n",
    "   if label >= 2:\n",
    "      indexList.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhbedoya/VirtualEnvs/SHMmae_venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(1.3527672, dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = indexList[321]\n",
    "print(InsistDataset[index][1])\n",
    "run_one_image(InsistDataset[index][0], model_mae, True)[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2327 [00:00<?, ?it/s]/home/yhbedoya/VirtualEnvs/SHMmae_venv/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "100%|██████████| 2327/2327 [01:24<00:00, 27.53it/s]\n"
     ]
    }
   ],
   "source": [
    "y = []\n",
    "y_pred = []\n",
    "\n",
    "for index in tqdm(range(len(InsistDataset))):\n",
    "    y.append(InsistDataset[index][1])\n",
    "    y_pred.append(run_one_image(InsistDataset[index][0], model_mae, True)[0][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25770495233716634"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((np.array(y) - np.array(y_pred)) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.331619903285154"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.abs(np.array(y) - np.array(y_pred))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('SHMmae_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ad81a87cda928bf31a314de06b951603fac3acce7ced8754b726311d2f5450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
