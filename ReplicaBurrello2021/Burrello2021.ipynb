{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import glob\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHMDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path, isPreTrain, isFineTuning, isEvaluation):\n",
    "        if isPreTrain:\n",
    "            self.start_time, self.end_time = \"05/12/2021 00:00\", \"05/12/2021 23:59\" #\"05/12/2021 00:00\", \"05/12/2021 23:59\"\n",
    "            self.datasetSize = 500000\n",
    "        elif isFineTuning:\n",
    "            self.start_time, self.end_time = \"06/12/2021 00:06\", \"06/12/2021 00:10\" #\"06/12/2021 00:00\", \"06/12/2021 11:59\"\n",
    "            self.datasetSize = 200000\n",
    "        elif isEvaluation:\n",
    "            self.start_time, self.end_time = \"06/12/2021 00:11\", \"06/12/2021 00:15\" #\"06/12/2021 12:00\", \"06/12/2021 17:59\"\n",
    "            self.datasetSize = 50000\n",
    "        else:\n",
    "            self.start_time, self.end_time = \"06/12/2021 00:21\", \"06/12/2021 00:25\" #\"06/12/2021 17:59\", \"06/12/2021 23:59\"\n",
    "            self.datasetSize = 50000\n",
    "        self.path = data_path #'/home/yhbedoya/Repositories/SHM-MAE/traffic/20211205/'\n",
    "        self.noisySensors = [\"C12.1.4\", \"C17.1.2\"]\n",
    "        self.minDuration = 0.25\n",
    "        self.data = self._readCSV()\n",
    "        self.distanceToSensor = self._readDistanceToSensor()\n",
    "        self.sensorVarDict = self._calculateThresholds(isPreTrain=isPreTrain)\n",
    "        self.pesaDataDf = self._readLabels()\n",
    "        self.labelsDf, self.groupsDf = self._labelAssignment()\n",
    "        self.sampleRate = 100\n",
    "        self.frameLength = 198\n",
    "        self.stepLength = 58\n",
    "        self.windowLength= 6000\n",
    "        self.windowStep = 1500\n",
    "        self.data, self.limits, self.totalWindows = self._partitioner()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.totalWindows\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.limits[index]\n",
    "\n",
    "    def _readCSV(self):\n",
    "        print(f'reading CSV files')\n",
    "        start = datetime.strptime(self.start_time, '%d/%m/%Y %H:%M')\n",
    "        end = datetime.strptime(self.end_time, '%d/%m/%Y %H:%M')\n",
    "\n",
    "        ldf = list()\n",
    "        for p in tqdm(glob.glob(self.path + \"*.csv\")):\n",
    "            name = os.path.split(p)[-1]\n",
    "            nstr = datetime.strptime(name, 'traffic_%Y%m%dH%H%M%S.csv')\n",
    "            if start <= nstr < end:\n",
    "                df_tmp = pd.read_csv(p)\n",
    "                c_drop = set(df_tmp.columns) - set([\"sens_pos\", \"x\", \"y\", \"z\", \"ts\"])\n",
    "                if len(c_drop) > 0:\n",
    "                    df_tmp.drop(columns=list(c_drop), inplace=True)\n",
    "                ldf.append(df_tmp)\n",
    "        df = pd.concat(ldf).sort_values(by=['sens_pos', 'ts'])\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        #df = df[df['sens_pos'].isin(self.sensors)]\n",
    "        df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "        df['Time'] = df['ts'].dt.strftime('%Y-%m-%d %H:%M:00')\n",
    "        df[\"xN\"] = df[\"x\"]-np.mean(df[\"x\"])\n",
    "        df[\"yN\"] = df[\"y\"]-np.mean(df[\"y\"])\n",
    "        df[\"zN\"] = df[\"z\"]-np.mean(df[\"z\"])\n",
    "        df[\"vars\"] = df[\"zN\"].rolling(window=100).var().fillna(0)\n",
    "        df[\"vars\"] = df[\"vars\"].rolling(window=100).mean().fillna(0)\n",
    "        print(f'finish reading process')\n",
    "        return df\n",
    "\n",
    "    def _readDistanceToSensor(self):\n",
    "        distanceToSensor = {}\n",
    "        with open('/home/yhbedoya/Repositories/SHM-MAE/LabelGeneration/distanceToSensor.csv') as f: #/home/yvelez/sacertis/distanceToSensor.csv\n",
    "            for line in f.readlines():\n",
    "                sensor, distance = line.replace(\"'\", \"\").replace(\"\\n\",\"\").split(\",\")\n",
    "                distanceToSensor[sensor] = float(distance)\n",
    "        return distanceToSensor\n",
    "\n",
    "    def _readLabels(self):\n",
    "        start_time = datetime.strptime(self.start_time, '%d/%m/%Y %H:%M')\n",
    "        end_time = datetime.strptime(self.end_time, '%d/%m/%Y %H:%M')\n",
    "        pesaDataDf = pd.read_csv(\"/home/yhbedoya/Repositories/SHM-MAE/dati_pese_dinamiche/dati 2021-12-04_2021-12-12 pesa km 104,450.csv\", sep=\";\", index_col=0) #/home/yvelez/sacertis/dati_pese_dinamiche/dati 2021-12-04_2021-12-12 pesa km 104,450.csv\n",
    "        pesaDataDf = pesaDataDf[[\"Id\", \"StartTimeStr\", \"ClassId\", \"GrossWeight\", \"Velocity\", \"VelocityUnit\"]]\n",
    "        pesaDataDf[\"Time\"] = pd.to_datetime(pesaDataDf[\"StartTimeStr\"])\n",
    "        pesaDataDf[\"Time\"] = pesaDataDf[\"Time\"].dt.strftime('%Y-%d-%m %H:%M:00')\n",
    "        pesaDataDf[\"Time\"] = pd.to_datetime(pesaDataDf[\"Time\"]) + pd.to_timedelta(-1,'H')\n",
    "        pesaDataDf.sort_values(by=\"Id\", inplace=True)\n",
    "        pesaDataDf = pesaDataDf[(pesaDataDf[\"Time\"]>=start_time) & (pesaDataDf[\"Time\"]<=end_time)]\n",
    "        pesaDataDf.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return pesaDataDf\n",
    "\n",
    "    def groupsGenerator(self, sensorData, minTime, maxTime, threshold):\n",
    "        slice = sensorData[(sensorData[\"ts\"]>= minTime) & (sensorData[\"ts\"]<= maxTime)]\n",
    "        \n",
    "        slice[\"outlier\"] = slice[\"vars\"].apply(lambda x: x>=threshold)\n",
    "        outliers = slice[slice[\"outlier\"] == True].reset_index().to_dict(\"records\")\n",
    "\n",
    "        if len(outliers) == 0:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        last = minTime\n",
    "        timeStart = outliers[0][\"ts\"]\n",
    "        flag = True\n",
    "        groups = []\n",
    "        groupTimes = []\n",
    "        groupIndexes = []\n",
    "        groupVars = []\n",
    "        label = np.nan\n",
    "        groupId = 0\n",
    "        for outlier in outliers:\n",
    "            if ((outlier[\"ts\"] - last).total_seconds() < 2) or flag:\n",
    "                groupTimes.append(outlier[\"ts\"])\n",
    "                groupVars.append(outlier[\"vars\"])\n",
    "                flag = False\n",
    "                timeEnd = outlier[\"ts\"]\n",
    "            else:\n",
    "                start, end = min(groupTimes), max(groupTimes)\n",
    "                groupSignal = sensorData[(sensorData[\"ts\"]>= start) & (sensorData[\"ts\"]<= end)][\"zN\"]\n",
    "                signalPower = np.sqrt(np.mean(np.array(groupSignal)**2))**2 \n",
    "                pointMaxVar = groupTimes[np.argmax(groupVars)]\n",
    "                if ((end - start).total_seconds() > self.minDuration):\n",
    "                    label = {\"groupId\": groupId,\"start\": start, \"end\": end, \"signalPower\": signalPower, \n",
    "                    \"pointMaxVar\": pointMaxVar}\n",
    "                    groups.append(label)\n",
    "                groupId += 1\n",
    "                groupTimes = [outlier[\"ts\"],]\n",
    "                groupVars = [outlier[\"vars\"],]\n",
    "            last = outlier[\"ts\"]\n",
    "\n",
    "        start, end = min(groupTimes), max(groupTimes)\n",
    "        groupSignal = sensorData[(sensorData[\"ts\"]>= start) & (sensorData[\"ts\"]<= end)][\"zN\"]\n",
    "        signalPower = np.sqrt(np.mean(np.array(groupSignal)**2))**2 \n",
    "        pointMaxVar = groupTimes[np.argmax(groupVars)]\n",
    "        if ((end-start).total_seconds() > self.minDuration):\n",
    "            label = {\"groupId\": groupId,\"start\": start, \"end\": end, \"signalPower\": signalPower, \n",
    "            \"pointMaxVar\": pointMaxVar}\n",
    "            groups.append(label)\n",
    "\n",
    "        if len(groups)>0:\n",
    "            groupsDf = pd.DataFrame(groups).sort_values(\"signalPower\", ascending=False)\n",
    "        else:\n",
    "            groupsDf = pd.DataFrame()\n",
    "\n",
    "        return groupsDf\n",
    "\n",
    "    def _labelAssignment(self,):\n",
    "        sensorLabelsDfList = []\n",
    "        groupsDfList = []\n",
    "\n",
    "        sensorsList = self.data[\"sens_pos\"].unique()\n",
    "        for sensor in sensorsList:\n",
    "            if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()) or (sensor not in self.sensorVarDict.keys()):\n",
    "                continue\n",
    "            assignedLabels = {}\n",
    "            assignedLabels2 = {}\n",
    "            sensorLabelsDf = self.pesaDataDf.copy(deep=True)\n",
    "            sensorLabelsDf[\"EstimatedTime\"] = sensorLabelsDf[\"Time\"] + pd.to_timedelta((float(self.distanceToSensor[sensor])/(sensorLabelsDf[\"Velocity\"]/3.6))-20,'S')\n",
    "            sensorLabelsDf[\"MaxTime\"] = sensorLabelsDf[\"EstimatedTime\"] + pd.to_timedelta(120,'S')\n",
    "            minTime = sensorLabelsDf[\"EstimatedTime\"].min()\n",
    "            maxTime = sensorLabelsDf[\"MaxTime\"].max()\n",
    "            sensorLabelsDf.sort_values(\"GrossWeight\", inplace=True, ascending=False)\n",
    "\n",
    "            sensorData = self.data[self.data[\"sens_pos\"]==sensor]\n",
    "            threshold = self.sensorVarDict[sensor][\"threshold\"]\n",
    "\n",
    "            groupsDf = self.groupsGenerator(sensorData, minTime, maxTime, threshold)\n",
    "            print(f\"Total groups found for sensor {sensor}: {groupsDf.shape[0]}\")\n",
    "            if groupsDf.empty:\n",
    "                continue\n",
    "\n",
    "            availableGroupsDf = groupsDf.copy(deep=True)\n",
    "            for index, row in sensorLabelsDf.iterrows():\n",
    "                if row[\"Id\"] in assignedLabels:\n",
    "                    continue\n",
    "                \n",
    "                if availableGroupsDf.empty:\n",
    "                    break\n",
    "\n",
    "                candidatesDf = availableGroupsDf[(row[\"EstimatedTime\"] <= availableGroupsDf[\"pointMaxVar\"]) & (availableGroupsDf[\"pointMaxVar\"] <= row[\"MaxTime\"])]\n",
    "                if not candidatesDf.empty:\n",
    "                    assignedLabels[row[\"Id\"]] = candidatesDf.iloc[0].to_dict()\n",
    "                    assignedLabels2[candidatesDf.iloc[0][\"groupId\"]] = row[\"Id\"]\n",
    "                    availableGroupsDf.drop(candidatesDf.index[0], inplace=True)\n",
    "            \n",
    "            sensorLabelsDf[\"sens_pos\"] = sensor\n",
    "            sensorLabelsDf[\"labels\"] = sensorLabelsDf.apply(lambda row: assignedLabels[row[\"Id\"]] if row[\"Id\"] in assignedLabels else np.nan, axis=1)\n",
    "            sensorLabelsDf.sort_values(\"Id\", inplace=True)\n",
    "            groupsDf[\"sens_pos\"] = sensor\n",
    "            groupsDf[\"labels\"] = groupsDf.apply(lambda row: assignedLabels2[row[\"groupId\"]] if row[\"groupId\"] in assignedLabels2 else np.nan, axis=1)\n",
    "            groupsDf.sort_values(\"groupId\", inplace=True)\n",
    "            groupsDf.dropna(inplace=True)\n",
    "\n",
    "            sensorLabelsDfList.append(sensorLabelsDf)\n",
    "            groupsDfList.append(groupsDf)\n",
    "\n",
    "        labelsDf = pd.concat(sensorLabelsDfList)\n",
    "        groupsDf =  pd.concat(groupsDfList)\n",
    "\n",
    "        print(f\"Total labels: {len(labelsDf)}\")\n",
    "        totnan = labelsDf[\"labels\"].isna().sum()\n",
    "        print(f\"Total nan labels: {totnan}\")\n",
    "        print(f\"Proportion of match labels: {1-(totnan/len(labelsDf))}\")\n",
    "\n",
    "        return labelsDf, groupsDf\n",
    "\n",
    "    def _labelAssigner(self, timeSlice, sensor):\n",
    "        start, end = timeSlice.min(), timeSlice.max()\n",
    "        vehiclesInSliceDf = self.groupsDf[(self.groupsDf[\"pointMaxVar\"]>=start) &\n",
    "        (self.groupsDf[\"pointMaxVar\"]<=end) &\n",
    "        (self.groupsDf[\"sens_pos\"]==sensor)]\n",
    "        return vehiclesInSliceDf.shape[0]\n",
    "\n",
    "    def _partitioner(self):\n",
    "        sensors = self.data['sens_pos'].unique().tolist()\n",
    "        print(f'start partitioner')\n",
    "        partitions = {}\n",
    "        cumulatedWindows = 0\n",
    "        limits = dict()\n",
    "        print(f'Generating windows')\n",
    "        for sensor in tqdm(sensors):\n",
    "            if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()):\n",
    "                continue\n",
    "            sensorData = self.data[self.data['sens_pos']==sensor]\n",
    "            totalFrames = sensorData.shape[0]\n",
    "            totalWindows = math.ceil((totalFrames-self.windowLength)/self.windowStep)\n",
    "            start = cumulatedWindows\n",
    "            cumulatedWindows += totalWindows\n",
    "            end = cumulatedWindows\n",
    "            indexStart = sensorData.index[0]\n",
    "            partitions[sensor]= (start, end, indexStart)\n",
    "\n",
    "        timeData = torch.tensor(self.data[\"z\"].values, dtype=torch.float64)\n",
    "        timestamps = self.data[\"ts\"]\n",
    "        cummulator = -1\n",
    "\n",
    "        print(f'Defining useful windows limits')\n",
    "        indexes = list(range(0, cumulatedWindows))\n",
    "        random.shuffle(indexes)\n",
    "        \n",
    "        for index in tqdm(indexes):\n",
    "            if cummulator >= self.datasetSize:\n",
    "                break\n",
    "            for sensor,v in partitions.items():\n",
    "                if index in range(v[0], v[1]):\n",
    "                    start = v[2]+(index-v[0])*self.windowStep\n",
    "                    timeSlice = timestamps[start: start+self.windowLength]\n",
    "                    label = self._labelAssigner(timeSlice, sensor)\n",
    "                    signalPower = self.power(timeData[start: start+self.windowLength])\n",
    "\n",
    "                    if (signalPower>1.25*10**-6) or (label>0):\n",
    "                        cummulator += 1\n",
    "                        limits[cummulator] = (start, start+self.windowLength, label, (timestamps[start], timestamps[start+self.windowLength]), sensor)\n",
    "\n",
    "                    break\n",
    "        print(f'Total windows in dataset: {cummulator}')\n",
    "        return timeData, limits, cummulator\n",
    "\n",
    "    def _transformation(self, slice):\n",
    "        sliceN = slice-torch.mean(slice)\n",
    "        frequencies, times, spectrogram = signal.spectrogram(sliceN,self.sampleRate,nfft=self.frameLength,noverlap=(self.frameLength - self.stepLength), nperseg=self.frameLength,mode='psd')\n",
    "\n",
    "        return frequencies, times, np.log10(spectrogram)\n",
    "    \n",
    "    def _normalizer(self, spectrogram):\n",
    "        spectrogramNorm = (spectrogram - self.min) / (self.max - self.min)\n",
    "        return spectrogramNorm\n",
    "\n",
    "    def power(self, slice):\n",
    "        return np.sqrt(np.mean(np.array(slice)**2))**2\n",
    "\n",
    "    def interquartileRule(self, data):\n",
    "        # Calculate the first quartile (Q1)\n",
    "        Q1 = np.percentile(data, 25)\n",
    "\n",
    "        # Calculate the third quartile (Q3)\n",
    "        Q3 = np.percentile(data, 75)\n",
    "\n",
    "        # Calculate the interquartile range (IQR)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        # Define the upper and lower bounds\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        return lower_bound, upper_bound\n",
    "\n",
    "    def _calculateThresholds(self, isPreTrain):\n",
    "        if isPreTrain:\n",
    "            print(f'Start creating thresholds')\n",
    "            varDf = self.data[[\"sens_pos\", \"vars\"]]\n",
    "            sensorsList = self.data[\"sens_pos\"].unique()\n",
    "            sensorVarDict = {}\n",
    "            for sensor in tqdm(sensorsList):\n",
    "                if (sensor in self.noisySensors) or (sensor not in self.distanceToSensor.keys()):\n",
    "                    continue\n",
    "                sensorVarDf = varDf[varDf[\"sens_pos\"]==sensor]\n",
    "                lower_bound, upper_bound = self.interquartileRule(sensorVarDf[\"vars\"])\n",
    "                sensorVarDf = sensorVarDf[(sensorVarDf[\"vars\"]>lower_bound) & (sensorVarDf[\"vars\"]<upper_bound)]\n",
    "                mean = sensorVarDf[\"vars\"].mean()\n",
    "                std = sensorVarDf[\"vars\"].std()\n",
    "                threshold = mean + 3.5 * std\n",
    "                sensorVarDict[sensor] = {\"mean\": mean, \"std\": std, \"threshold\": threshold}\n",
    "                #with open(\"/content/drive/MyDrive/Data Science and Engineering - PoliTo2/Thesis/models/MAE-SHM/output_dir_TE/sensorVarDict.json\", \"w\") as f:\n",
    "                #    # Write the dict to the file\n",
    "                #    json.dump(sensorVarDict, f)\n",
    "            print(f'Finish thresholds creation')\n",
    "        else:\n",
    "            print(f'Start reading thresholds')\n",
    "            with open(\"/home/yhbedoya/Repositories/SHM-MAE/util/DataLoadersSacertisLabels/sensorVarDict.json\", \"r\") as f: #/home/yvelez/sacertis/sensorVarDict.json\n",
    "                # Load the dict from the file\n",
    "                sensorVarDict = json.load(f)\n",
    "\n",
    "            print(f'Finish thresholds reading')\n",
    "\n",
    "        return sensorVarDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupAssigner(row, groupsDict):\n",
    "    sensor = row[\"sensor\"]\n",
    "    for k, v in groupsDict.items():\n",
    "        if sensor in v:\n",
    "            return int(k)\n",
    "        \n",
    "def featureExtraction(window, sensNumber):\n",
    "    statistics = dict()\n",
    "    axis = [\"xN\", \"yN\", \"zN\"]\n",
    "    for ax in axis:\n",
    "        axSens = ax + sensNumber\n",
    "        serie = window[ax]\n",
    "\n",
    "        axStatistics={\n",
    "            axSens+\"mean\": np.mean(serie),\n",
    "            axSens+\"std\": np.std(serie),\n",
    "            axSens+\"min\": np.min(serie),\n",
    "            axSens+\"max\": np.max(serie),\n",
    "            axSens+\"med\": np.median(serie),\n",
    "            axSens+\"kurt\": stats.kurtosis(serie),\n",
    "            axSens+\"skew\": stats.skew(serie),\n",
    "            axSens+\"rms\": np.sqrt(np.mean(serie**2)),\n",
    "            axSens+\"sabs\": np.sum(np.abs(serie)),\n",
    "            axSens+\"eom\": serie[serie>np.mean(serie)].sum(),\n",
    "            axSens+\"ener\": np.sqrt(np.mean(np.array(serie)**2))**2,\n",
    "            axSens+\"mad\": np.median(np.absolute(serie - np.median(serie)))\n",
    "        }\n",
    "\n",
    "        statistics = {**statistics, **axStatistics}\n",
    "\n",
    "    return statistics\n",
    "\n",
    "def getDataset(training=False, evaluation=False, test=False):\n",
    "\n",
    "    data_path = \"/home/yhbedoya/Repositories/SHM-MAE/traffic/20211206/\"\n",
    "    dataGenerator = SHMDataset(data_path=data_path ,isPreTrain=False, isFineTuning=training, isEvaluation=evaluation)\n",
    "\n",
    "    windows = {\"indexStart\":[],\n",
    "        \"indexEnd\":[],\n",
    "        \"times\": [],\n",
    "        \"label\":[],\n",
    "        \"sensor\":[]}\n",
    "\n",
    "    for i in tqdm(range(len(dataGenerator))):\n",
    "        start, end, label, timeSlice, sensor = dataGenerator[i]\n",
    "        windows[\"indexStart\"].append(start)\n",
    "        windows[\"indexEnd\"].append(end)\n",
    "        windows[\"label\"].append(label)\n",
    "        windows[\"times\"].append(timeSlice)\n",
    "        windows[\"sensor\"].append(sensor)\n",
    "\n",
    "    df = dataGenerator._readCSV()\n",
    "    df = df[[\"sens_pos\", \"ts\", \"xN\", \"yN\", \"zN\"]]\n",
    "\n",
    "    sensors = df[\"sens_pos\"].unique()\n",
    "\n",
    "    groupsDict = {}\n",
    "    for sensor in list(sensors):\n",
    "        section = sensor.split(\".\")[0]\n",
    "        group = section[1:]\n",
    "\n",
    "        if section[0] == \"P\":\n",
    "            continue  \n",
    "        if int(group) in groupsDict.keys():\n",
    "            groupsDict[int(group)].append(sensor)\n",
    "        else:\n",
    "            groupsDict[int(group)] = [sensor]\n",
    "\n",
    "    toDelete = list()\n",
    "    for k, v in groupsDict.items():\n",
    "        if len(v) != 6:\n",
    "            toDelete.append(k)\n",
    "\n",
    "    for k in toDelete:\n",
    "        del groupsDict[k]\n",
    "            \n",
    "    windowsDf = pd.DataFrame(windows)\n",
    "            \n",
    "    windowsDf[\"group\"] = windowsDf.apply(groupAssigner, groupsDict = groupsDict, axis=1)\n",
    "    windowsDf.dropna(inplace=True)\n",
    "\n",
    "    extractedFeaturesList = []\n",
    "    group = 2\n",
    "    groupDataDf = df[df[\"sens_pos\"].isin(groupsDict[group])]\n",
    "    groupWindowsDf = windowsDf[windowsDf[\"group\"]==group]\n",
    "    for index, row in tqdm(groupWindowsDf.iterrows()):\n",
    "        statistics = dict()\n",
    "        section = row[\"sensor\"].split(\".\")[0]\n",
    "        group = section[1:]\n",
    "        \n",
    "        if group ==\"8\":\n",
    "            continue\n",
    "        window = groupDataDf[(groupDataDf[\"ts\"] >= row[\"times\"][0]) & (groupDataDf[\"ts\"] < row[\"times\"][1])]\n",
    "        for sensor in groupsDict[int(group)]:\n",
    "            sensorWindow =  window[window[\"sens_pos\"]==row[\"sensor\"]]\n",
    "            sensorStatistics = featureExtraction(sensorWindow, sensor[-3:])\n",
    "            statistics = {**statistics, **sensorStatistics}\n",
    "        statistics[\"label\"] = row[\"label\"]\n",
    "\n",
    "        extractedFeaturesList.append(statistics)\n",
    "\n",
    "    dataDf = pd.DataFrame(extractedFeaturesList)\n",
    "    return dataDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:05<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n",
      "Start reading thresholds\n",
      "Finish thresholds reading\n",
      "Total groups found for sensor C1.1.1: 1\n",
      "Total groups found for sensor C1.1.2: 8\n",
      "Total groups found for sensor C1.1.3: 1\n",
      "Total groups found for sensor C1.2.1: 2\n",
      "Total groups found for sensor C1.2.2: 1\n",
      "Total groups found for sensor C1.2.3: 2\n",
      "Total groups found for sensor C10.1.2: 0\n",
      "Total groups found for sensor C10.1.3: 8\n",
      "Total groups found for sensor C10.1.4: 3\n",
      "Total groups found for sensor C10.2.2: 3\n",
      "Total groups found for sensor C10.2.3: 2\n",
      "Total groups found for sensor C10.2.4: 1\n",
      "Total groups found for sensor C11.1.2: 1\n",
      "Total groups found for sensor C11.1.3: 1\n",
      "Total groups found for sensor C11.1.4: 1\n",
      "Total groups found for sensor C11.2.2: 0\n",
      "Total groups found for sensor C11.2.3: 2\n",
      "Total groups found for sensor C11.2.4: 1\n",
      "Total groups found for sensor C12.1.2: 2\n",
      "Total groups found for sensor C12.1.3: 3\n",
      "Total groups found for sensor C12.2.2: 2\n",
      "Total groups found for sensor C12.2.3: 1\n",
      "Total groups found for sensor C12.2.4: 1\n",
      "Total groups found for sensor C13.1.2: 5\n",
      "Total groups found for sensor C13.1.3: 1\n",
      "Total groups found for sensor C13.1.4: 2\n",
      "Total groups found for sensor C13.2.2: 1\n",
      "Total groups found for sensor C13.2.3: 1\n",
      "Total groups found for sensor C13.2.4: 1\n",
      "Total groups found for sensor C14.1.2: 1\n",
      "Total groups found for sensor C14.1.3: 1\n",
      "Total groups found for sensor C14.1.4: 1\n",
      "Total groups found for sensor C14.2.2: 0\n",
      "Total groups found for sensor C14.2.3: 1\n",
      "Total groups found for sensor C14.2.4: 2\n",
      "Total groups found for sensor C15.1.2: 2\n",
      "Total groups found for sensor C15.1.3: 1\n",
      "Total groups found for sensor C15.1.4: 2\n",
      "Total groups found for sensor C15.2.2: 1\n",
      "Total groups found for sensor C15.2.3: 1\n",
      "Total groups found for sensor C15.2.4: 1\n",
      "Total groups found for sensor C16.1.2: 0\n",
      "Total groups found for sensor C16.1.3: 2\n",
      "Total groups found for sensor C16.1.4: 1\n",
      "Total groups found for sensor C16.2.2: 1\n",
      "Total groups found for sensor C16.2.3: 1\n",
      "Total groups found for sensor C16.2.4: 2\n",
      "Total groups found for sensor C17.1.3: 1\n",
      "Total groups found for sensor C17.1.4: 2\n",
      "Total groups found for sensor C17.2.2: 2\n",
      "Total groups found for sensor C17.2.4: 1\n",
      "Total groups found for sensor C18.1.2: 1\n",
      "Total groups found for sensor C18.1.3: 1\n",
      "Total groups found for sensor C18.1.4: 2\n",
      "Total groups found for sensor C18.2.2: 1\n",
      "Total groups found for sensor C18.2.3: 2\n",
      "Total groups found for sensor C18.2.4: 1\n",
      "Total groups found for sensor C2.1.2: 1\n",
      "Total groups found for sensor C2.1.3: 1\n",
      "Total groups found for sensor C2.1.4: 1\n",
      "Total groups found for sensor C2.2.2: 1\n",
      "Total groups found for sensor C2.2.3: 1\n",
      "Total groups found for sensor C2.2.4: 1\n",
      "Total groups found for sensor C3.1.2: 2\n",
      "Total groups found for sensor C3.1.3: 1\n",
      "Total groups found for sensor C3.1.4: 2\n",
      "Total groups found for sensor C3.2.2: 1\n",
      "Total groups found for sensor C3.2.3: 2\n",
      "Total groups found for sensor C3.2.4: 7\n",
      "Total groups found for sensor C4.1.2: 1\n",
      "Total groups found for sensor C4.1.3: 4\n",
      "Total groups found for sensor C4.1.4: 1\n",
      "Total groups found for sensor C4.2.2: 2\n",
      "Total groups found for sensor C4.2.3: 1\n",
      "Total groups found for sensor C4.2.4: 1\n",
      "Total groups found for sensor C5.1.2: 1\n",
      "Total groups found for sensor C5.1.3: 2\n",
      "Total groups found for sensor C5.1.4: 1\n",
      "Total groups found for sensor C5.2.2: 3\n",
      "Total groups found for sensor C5.2.3: 8\n",
      "Total groups found for sensor C5.2.4: 1\n",
      "Total groups found for sensor C6.1.2: 1\n",
      "Total groups found for sensor C6.1.3: 0\n",
      "Total groups found for sensor C6.1.4: 2\n",
      "Total groups found for sensor C6.2.2: 1\n",
      "Total groups found for sensor C6.2.3: 1\n",
      "Total groups found for sensor C6.2.4: 5\n",
      "Total groups found for sensor C7.1.2: 1\n",
      "Total groups found for sensor C7.1.3: 1\n",
      "Total groups found for sensor C7.1.4: 1\n",
      "Total groups found for sensor C7.2.2: 0\n",
      "Total groups found for sensor C7.2.3: 4\n",
      "Total groups found for sensor C7.2.4: 6\n",
      "Total groups found for sensor C8.1.2: 1\n",
      "Total groups found for sensor C8.1.3: 1\n",
      "Total groups found for sensor C8.1.4: 2\n",
      "Total groups found for sensor C8.2.2: 1\n",
      "Total groups found for sensor C8.2.4: 2\n",
      "Total groups found for sensor C9.1.2: 1\n",
      "Total groups found for sensor C9.1.3: 1\n",
      "Total groups found for sensor C9.1.4: 1\n",
      "Total groups found for sensor C9.2.2: 1\n",
      "Total groups found for sensor C9.2.4: 1\n",
      "Total labels: 97\n",
      "Total nan labels: 0\n",
      "Proportion of match labels: 1.0\n",
      "start partitioner\n",
      "Generating windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining useful windows limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1155/1155 [00:02<00:00, 470.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in dataset: 1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1154/1154 [00:00<00:00, 573554.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:05<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:07,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:06<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n",
      "Start reading thresholds\n",
      "Finish thresholds reading\n",
      "Total groups found for sensor C1.1.1: 0\n",
      "Total groups found for sensor C1.1.2: 6\n",
      "Total groups found for sensor C1.1.3: 0\n",
      "Total groups found for sensor C1.2.1: 0\n",
      "Total groups found for sensor C1.2.2: 0\n",
      "Total groups found for sensor C1.2.3: 1\n",
      "Total groups found for sensor C10.1.2: 0\n",
      "Total groups found for sensor C10.1.3: 0\n",
      "Total groups found for sensor C10.1.4: 0\n",
      "Total groups found for sensor C10.2.2: 0\n",
      "Total groups found for sensor C10.2.3: 0\n",
      "Total groups found for sensor C10.2.4: 0\n",
      "Total groups found for sensor C11.1.2: 0\n",
      "Total groups found for sensor C11.1.3: 0\n",
      "Total groups found for sensor C11.1.4: 0\n",
      "Total groups found for sensor C11.2.2: 0\n",
      "Total groups found for sensor C11.2.3: 0\n",
      "Total groups found for sensor C11.2.4: 0\n",
      "Total groups found for sensor C12.1.2: 0\n",
      "Total groups found for sensor C12.1.3: 1\n",
      "Total groups found for sensor C12.2.2: 3\n",
      "Total groups found for sensor C12.2.3: 0\n",
      "Total groups found for sensor C12.2.4: 0\n",
      "Total groups found for sensor C13.1.2: 0\n",
      "Total groups found for sensor C13.1.3: 0\n",
      "Total groups found for sensor C13.1.4: 0\n",
      "Total groups found for sensor C13.2.2: 0\n",
      "Total groups found for sensor C13.2.3: 0\n",
      "Total groups found for sensor C13.2.4: 0\n",
      "Total groups found for sensor C14.1.2: 0\n",
      "Total groups found for sensor C14.1.3: 0\n",
      "Total groups found for sensor C14.1.4: 0\n",
      "Total groups found for sensor C14.2.2: 0\n",
      "Total groups found for sensor C14.2.3: 0\n",
      "Total groups found for sensor C14.2.4: 0\n",
      "Total groups found for sensor C15.1.2: 0\n",
      "Total groups found for sensor C15.1.3: 0\n",
      "Total groups found for sensor C15.1.4: 1\n",
      "Total groups found for sensor C15.2.2: 1\n",
      "Total groups found for sensor C15.2.3: 0\n",
      "Total groups found for sensor C15.2.4: 0\n",
      "Total groups found for sensor C16.1.2: 0\n",
      "Total groups found for sensor C16.1.3: 0\n",
      "Total groups found for sensor C16.1.4: 0\n",
      "Total groups found for sensor C16.2.2: 0\n",
      "Total groups found for sensor C16.2.3: 0\n",
      "Total groups found for sensor C16.2.4: 0\n",
      "Total groups found for sensor C17.1.3: 0\n",
      "Total groups found for sensor C17.1.4: 0\n",
      "Total groups found for sensor C17.2.2: 1\n",
      "Total groups found for sensor C17.2.4: 0\n",
      "Total groups found for sensor C18.1.2: 0\n",
      "Total groups found for sensor C18.1.3: 0\n",
      "Total groups found for sensor C18.1.4: 0\n",
      "Total groups found for sensor C18.2.2: 0\n",
      "Total groups found for sensor C18.2.3: 0\n",
      "Total groups found for sensor C18.2.4: 1\n",
      "Total groups found for sensor C2.1.2: 0\n",
      "Total groups found for sensor C2.1.3: 0\n",
      "Total groups found for sensor C2.1.4: 1\n",
      "Total groups found for sensor C2.2.2: 0\n",
      "Total groups found for sensor C2.2.3: 0\n",
      "Total groups found for sensor C2.2.4: 0\n",
      "Total groups found for sensor C3.1.2: 0\n",
      "Total groups found for sensor C3.1.3: 0\n",
      "Total groups found for sensor C3.1.4: 0\n",
      "Total groups found for sensor C3.2.2: 0\n",
      "Total groups found for sensor C3.2.3: 0\n",
      "Total groups found for sensor C3.2.4: 1\n",
      "Total groups found for sensor C4.1.2: 0\n",
      "Total groups found for sensor C4.1.3: 3\n",
      "Total groups found for sensor C4.1.4: 0\n",
      "Total groups found for sensor C4.2.2: 0\n",
      "Total groups found for sensor C4.2.3: 0\n",
      "Total groups found for sensor C4.2.4: 1\n",
      "Total groups found for sensor C5.1.2: 0\n",
      "Total groups found for sensor C5.1.3: 0\n",
      "Total groups found for sensor C5.1.4: 0\n",
      "Total groups found for sensor C5.2.2: 0\n",
      "Total groups found for sensor C5.2.3: 7\n",
      "Total groups found for sensor C5.2.4: 0\n",
      "Total groups found for sensor C6.1.2: 0\n",
      "Total groups found for sensor C6.1.3: 2\n",
      "Total groups found for sensor C6.1.4: 0\n",
      "Total groups found for sensor C6.2.2: 0\n",
      "Total groups found for sensor C6.2.3: 0\n",
      "Total groups found for sensor C6.2.4: 1\n",
      "Total groups found for sensor C7.1.2: 0\n",
      "Total groups found for sensor C7.1.3: 1\n",
      "Total groups found for sensor C7.1.4: 1\n",
      "Total groups found for sensor C7.2.2: 0\n",
      "Total groups found for sensor C7.2.3: 3\n",
      "Total groups found for sensor C7.2.4: 4\n",
      "Total groups found for sensor C8.1.2: 0\n",
      "Total groups found for sensor C8.1.3: 0\n",
      "Total groups found for sensor C8.1.4: 0\n",
      "Total groups found for sensor C8.2.2: 0\n",
      "Total groups found for sensor C8.2.4: 0\n",
      "Total groups found for sensor C9.1.2: 0\n",
      "Total groups found for sensor C9.1.3: 0\n",
      "Total groups found for sensor C9.1.4: 0\n",
      "Total groups found for sensor C9.2.2: 0\n",
      "Total groups found for sensor C9.2.4: 0\n",
      "Total labels: 19\n",
      "Total nan labels: 0\n",
      "Proportion of match labels: 1.0\n",
      "start partitioner\n",
      "Generating windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:40<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining useful windows limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1575/1575 [00:03<00:00, 456.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in dataset: 1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1574/1574 [00:00<00:00, 450760.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:06<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:10,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:05<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n",
      "Start reading thresholds\n",
      "Finish thresholds reading\n",
      "Total groups found for sensor C1.1.1: 1\n",
      "Total groups found for sensor C1.1.2: 13\n",
      "Total groups found for sensor C1.1.3: 0\n",
      "Total groups found for sensor C1.2.1: 1\n",
      "Total groups found for sensor C1.2.2: 1\n",
      "Total groups found for sensor C1.2.3: 1\n",
      "Total groups found for sensor C10.1.2: 2\n",
      "Total groups found for sensor C10.1.3: 5\n",
      "Total groups found for sensor C10.1.4: 1\n",
      "Total groups found for sensor C10.2.2: 2\n",
      "Total groups found for sensor C10.2.3: 1\n",
      "Total groups found for sensor C10.2.4: 1\n",
      "Total groups found for sensor C11.1.2: 1\n",
      "Total groups found for sensor C11.1.3: 1\n",
      "Total groups found for sensor C11.1.4: 1\n",
      "Total groups found for sensor C11.2.2: 0\n",
      "Total groups found for sensor C11.2.3: 1\n",
      "Total groups found for sensor C11.2.4: 1\n",
      "Total groups found for sensor C12.1.2: 1\n",
      "Total groups found for sensor C12.1.3: 7\n",
      "Total groups found for sensor C12.2.2: 5\n",
      "Total groups found for sensor C12.2.3: 1\n",
      "Total groups found for sensor C12.2.4: 1\n",
      "Total groups found for sensor C13.1.2: 1\n",
      "Total groups found for sensor C13.1.3: 2\n",
      "Total groups found for sensor C13.1.4: 1\n",
      "Total groups found for sensor C13.2.2: 1\n",
      "Total groups found for sensor C13.2.3: 5\n",
      "Total groups found for sensor C13.2.4: 1\n",
      "Total groups found for sensor C14.1.2: 1\n",
      "Total groups found for sensor C14.1.3: 1\n",
      "Total groups found for sensor C14.1.4: 1\n",
      "Total groups found for sensor C14.2.2: 0\n",
      "Total groups found for sensor C14.2.3: 1\n",
      "Total groups found for sensor C14.2.4: 1\n",
      "Total groups found for sensor C15.1.2: 6\n",
      "Total groups found for sensor C15.1.3: 5\n",
      "Total groups found for sensor C15.1.4: 6\n",
      "Total groups found for sensor C15.2.2: 1\n",
      "Total groups found for sensor C15.2.3: 1\n",
      "Total groups found for sensor C15.2.4: 1\n",
      "Total groups found for sensor C16.1.2: 1\n",
      "Total groups found for sensor C16.1.3: 2\n",
      "Total groups found for sensor C16.1.4: 1\n",
      "Total groups found for sensor C16.2.2: 1\n",
      "Total groups found for sensor C16.2.3: 1\n",
      "Total groups found for sensor C16.2.4: 1\n",
      "Total groups found for sensor C17.1.3: 1\n",
      "Total groups found for sensor C17.1.4: 1\n",
      "Total groups found for sensor C17.2.2: 1\n",
      "Total groups found for sensor C17.2.4: 1\n",
      "Total groups found for sensor C18.1.2: 2\n",
      "Total groups found for sensor C18.1.3: 1\n",
      "Total groups found for sensor C18.1.4: 1\n",
      "Total groups found for sensor C18.2.2: 1\n",
      "Total groups found for sensor C18.2.3: 1\n",
      "Total groups found for sensor C18.2.4: 2\n",
      "Total groups found for sensor C2.1.2: 1\n",
      "Total groups found for sensor C2.1.3: 1\n",
      "Total groups found for sensor C2.1.4: 2\n",
      "Total groups found for sensor C2.2.2: 3\n",
      "Total groups found for sensor C2.2.3: 1\n",
      "Total groups found for sensor C2.2.4: 1\n",
      "Total groups found for sensor C3.1.2: 2\n",
      "Total groups found for sensor C3.1.3: 2\n",
      "Total groups found for sensor C3.1.4: 1\n",
      "Total groups found for sensor C3.2.2: 1\n",
      "Total groups found for sensor C3.2.3: 6\n",
      "Total groups found for sensor C3.2.4: 5\n",
      "Total groups found for sensor C4.1.2: 1\n",
      "Total groups found for sensor C4.1.3: 4\n",
      "Total groups found for sensor C4.1.4: 2\n",
      "Total groups found for sensor C4.2.2: 2\n",
      "Total groups found for sensor C4.2.3: 1\n",
      "Total groups found for sensor C4.2.4: 1\n",
      "Total groups found for sensor C5.1.2: 1\n",
      "Total groups found for sensor C5.1.3: 4\n",
      "Total groups found for sensor C5.1.4: 1\n",
      "Total groups found for sensor C5.2.2: 1\n",
      "Total groups found for sensor C5.2.3: 1\n",
      "Total groups found for sensor C5.2.4: 5\n",
      "Total groups found for sensor C6.1.2: 1\n",
      "Total groups found for sensor C6.1.3: 0\n",
      "Total groups found for sensor C6.1.4: 1\n",
      "Total groups found for sensor C6.2.2: 1\n",
      "Total groups found for sensor C6.2.3: 1\n",
      "Total groups found for sensor C6.2.4: 2\n",
      "Total groups found for sensor C7.1.2: 1\n",
      "Total groups found for sensor C7.1.3: 1\n",
      "Total groups found for sensor C7.1.4: 1\n",
      "Total groups found for sensor C7.2.2: 0\n",
      "Total groups found for sensor C7.2.3: 5\n",
      "Total groups found for sensor C7.2.4: 9\n",
      "Total groups found for sensor C8.1.2: 2\n",
      "Total groups found for sensor C8.1.3: 1\n",
      "Total groups found for sensor C8.1.4: 1\n",
      "Total groups found for sensor C8.2.2: 1\n",
      "Total groups found for sensor C8.2.4: 2\n",
      "Total groups found for sensor C9.1.2: 1\n",
      "Total groups found for sensor C9.1.3: 1\n",
      "Total groups found for sensor C9.1.4: 1\n",
      "Total groups found for sensor C9.2.2: 1\n",
      "Total groups found for sensor C9.2.4: 1\n",
      "Total labels: 98\n",
      "Total nan labels: 0\n",
      "Proportion of match labels: 1.0\n",
      "start partitioner\n",
      "Generating windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:30<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining useful windows limits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1155/1155 [00:02<00:00, 479.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows in dataset: 1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1154/1154 [00:00<00:00, 345804.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading CSV files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:04<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish reading process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:07,  8.32it/s]\n"
     ]
    }
   ],
   "source": [
    "trainDf = getDataset(training=True, evaluation=False, test=False)\n",
    "evalDf = getDataset(training=False, evaluation=True, test=False)\n",
    "testDf = getDataset(training=False, evaluation=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xN1.2mean</th>\n",
       "      <th>xN1.2std</th>\n",
       "      <th>xN1.2min</th>\n",
       "      <th>xN1.2max</th>\n",
       "      <th>xN1.2med</th>\n",
       "      <th>xN1.2kurt</th>\n",
       "      <th>xN1.2skew</th>\n",
       "      <th>xN1.2rms</th>\n",
       "      <th>xN1.2sabs</th>\n",
       "      <th>xN1.2eom</th>\n",
       "      <th>...</th>\n",
       "      <th>zN2.4max</th>\n",
       "      <th>zN2.4med</th>\n",
       "      <th>zN2.4kurt</th>\n",
       "      <th>zN2.4skew</th>\n",
       "      <th>zN2.4rms</th>\n",
       "      <th>zN2.4sabs</th>\n",
       "      <th>zN2.4eom</th>\n",
       "      <th>zN2.4ener</th>\n",
       "      <th>zN2.4mad</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.016306</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-0.017431</td>\n",
       "      <td>-0.015294</td>\n",
       "      <td>-0.016286</td>\n",
       "      <td>3.691886</td>\n",
       "      <td>-0.057042</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>97.834603</td>\n",
       "      <td>-53.141577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000710</td>\n",
       "      <td>-0.002083</td>\n",
       "      <td>-0.146670</td>\n",
       "      <td>-0.056111</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>12.482324</td>\n",
       "      <td>-4.932020</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>3.337144</td>\n",
       "      <td>0.137020</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>5.216897</td>\n",
       "      <td>3.371172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.015541</td>\n",
       "      <td>-0.422639</td>\n",
       "      <td>-0.102635</td>\n",
       "      <td>0.015571</td>\n",
       "      <td>93.384389</td>\n",
       "      <td>47.663628</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035912</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.034908</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>2.657631</td>\n",
       "      <td>-0.046561</td>\n",
       "      <td>0.035912</td>\n",
       "      <td>215.470654</td>\n",
       "      <td>91.028549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>-0.014825</td>\n",
       "      <td>-0.029816</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.014794</td>\n",
       "      <td>88.748517</td>\n",
       "      <td>-42.504153</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014408</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.015523</td>\n",
       "      <td>-0.013540</td>\n",
       "      <td>-0.014379</td>\n",
       "      <td>2.856051</td>\n",
       "      <td>-0.195952</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>86.445879</td>\n",
       "      <td>-45.417206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.410406</td>\n",
       "      <td>0.012688</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>25.640483</td>\n",
       "      <td>-11.446887</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014412</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.015447</td>\n",
       "      <td>-0.013540</td>\n",
       "      <td>-0.014379</td>\n",
       "      <td>2.649339</td>\n",
       "      <td>-0.148002</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>86.474261</td>\n",
       "      <td>-44.045984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.446935</td>\n",
       "      <td>0.013276</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>25.793913</td>\n",
       "      <td>-13.163433</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.026493</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.027578</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.026510</td>\n",
       "      <td>1.897039</td>\n",
       "      <td>0.186729</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>158.958887</td>\n",
       "      <td>-70.480968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>0.087199</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>0.012081</td>\n",
       "      <td>72.459921</td>\n",
       "      <td>37.346088</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-0.016300</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.018804</td>\n",
       "      <td>-0.012624</td>\n",
       "      <td>-0.016286</td>\n",
       "      <td>44.261883</td>\n",
       "      <td>1.084675</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>97.797447</td>\n",
       "      <td>-54.325014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>-0.002083</td>\n",
       "      <td>1.158004</td>\n",
       "      <td>0.320081</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>12.239394</td>\n",
       "      <td>-4.996579</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-0.014364</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-0.015676</td>\n",
       "      <td>-0.013463</td>\n",
       "      <td>-0.014379</td>\n",
       "      <td>4.192638</td>\n",
       "      <td>-0.349802</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>86.186704</td>\n",
       "      <td>-37.142354</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002999</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>-0.012649</td>\n",
       "      <td>-0.022983</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>25.752256</td>\n",
       "      <td>-11.247154</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.014406</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.015447</td>\n",
       "      <td>-0.013540</td>\n",
       "      <td>-0.014379</td>\n",
       "      <td>2.273216</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>86.433214</td>\n",
       "      <td>-45.369034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002770</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>0.435489</td>\n",
       "      <td>-0.003216</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>25.813750</td>\n",
       "      <td>-13.043657</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.016280</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.017354</td>\n",
       "      <td>-0.015218</td>\n",
       "      <td>-0.016286</td>\n",
       "      <td>4.411478</td>\n",
       "      <td>0.104460</td>\n",
       "      <td>0.016281</td>\n",
       "      <td>97.679495</td>\n",
       "      <td>-39.086174</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>-0.068229</td>\n",
       "      <td>0.004841</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>11.463402</td>\n",
       "      <td>-4.603461</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    xN1.2mean  xN1.2std  xN1.2min  xN1.2max  xN1.2med  xN1.2kurt  xN1.2skew  \\\n",
       "0   -0.016306  0.000155 -0.017431 -0.015294 -0.016286   3.691886  -0.057042   \n",
       "1    0.000869  0.000150  0.000041  0.002177  0.000880   3.337144   0.137020   \n",
       "2    0.035912  0.000137  0.034908  0.036662  0.035900   2.657631  -0.046561   \n",
       "3   -0.014408  0.000153 -0.015523 -0.013540 -0.014379   2.856051  -0.195952   \n",
       "4   -0.014412  0.000154 -0.015447 -0.013540 -0.014379   2.649339  -0.148002   \n",
       "..        ...       ...       ...       ...       ...        ...        ...   \n",
       "61  -0.026493  0.000165 -0.027578 -0.025289 -0.026510   1.897039   0.186729   \n",
       "62  -0.016300  0.000209 -0.018804 -0.012624 -0.016286  44.261883   1.084675   \n",
       "63  -0.014364  0.000151 -0.015676 -0.013463 -0.014379   4.192638  -0.349802   \n",
       "64  -0.014406  0.000152 -0.015447 -0.013540 -0.014379   2.273216  -0.108447   \n",
       "65  -0.016280  0.000154 -0.017354 -0.015218 -0.016286   4.411478   0.104460   \n",
       "\n",
       "    xN1.2rms   xN1.2sabs   xN1.2eom  ...  zN2.4max  zN2.4med  zN2.4kurt  \\\n",
       "0   0.016307   97.834603 -53.141577  ... -0.000710 -0.002083  -0.146670   \n",
       "1   0.000882    5.216897   3.371172  ...  0.017067  0.015541  -0.422639   \n",
       "2   0.035912  215.470654  91.028549  ... -0.013680 -0.014825  -0.029816   \n",
       "3   0.014408   86.445879 -45.417206  ... -0.002770 -0.004296   0.410406   \n",
       "4   0.014413   86.474261 -44.045984  ... -0.002770 -0.004296   0.446935   \n",
       "..       ...         ...        ...  ...       ...       ...        ...   \n",
       "61  0.026494  158.958887 -70.480968  ...  0.013633  0.012107   0.087199   \n",
       "62  0.016301   97.797447 -54.325014  ...  0.000740 -0.002083   1.158004   \n",
       "63  0.014365   86.186704 -37.142354  ... -0.002999 -0.004296  -0.012649   \n",
       "64  0.014406   86.433214 -45.369034  ... -0.002770 -0.004296   0.435489   \n",
       "65  0.016281   97.679495 -39.086174  ... -0.000558 -0.001931  -0.068229   \n",
       "\n",
       "    zN2.4skew  zN2.4rms  zN2.4sabs   zN2.4eom  zN2.4ener  zN2.4mad  label  \n",
       "0   -0.056111  0.002114  12.482324  -4.932020   0.000004  0.000229      0  \n",
       "1   -0.102635  0.015571  93.384389  47.663628   0.000242  0.000305      0  \n",
       "2    0.068818  0.014794  88.748517 -42.504153   0.000219  0.000229      0  \n",
       "3    0.012688  0.004287  25.640483 -11.446887   0.000018  0.000229      1  \n",
       "4    0.013276  0.004312  25.793913 -13.163433   0.000019  0.000229      1  \n",
       "..        ...       ...        ...        ...        ...       ...    ...  \n",
       "61   0.042352  0.012081  72.459921  37.346088   0.000146  0.000229      0  \n",
       "62   0.320081  0.002084  12.239394  -4.996579   0.000004  0.000305      1  \n",
       "63  -0.022983  0.004304  25.752256 -11.247154   0.000019  0.000229      0  \n",
       "64  -0.003216  0.004316  25.813750 -13.043657   0.000019  0.000229      1  \n",
       "65   0.004841  0.001950  11.463402  -4.603461   0.000004  0.000229      0  \n",
       "\n",
       "[66 rows x 217 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zN1.2kurt', 'zN1.3kurt', 'xN1.4skew', 'zN1.4kurt', 'xN2.2skew', 'zN2.2kurt', 'xN2.3skew', 'zN2.3kurt', 'xN2.4skew', 'zN2.4kurt', 'label']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Separate your features and target variable\n",
    "X = trainDf.drop('label', axis=1)\n",
    "y = trainDf['label']\n",
    "\n",
    "# Select the k best features using the F-test\n",
    "selector = SelectKBest(score_func=f_classif, k=10) # choose the number of features you want to keep\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "# Get the indices of the selected features\n",
    "mask = selector.get_support() # an array of booleans indicating which features are selected\n",
    "selected_features = list(X.columns[mask]) + [\"label\"] # a list of the selected feature names\n",
    "\n",
    "\n",
    "# Print the selected features\n",
    "print(list(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFDf = trainDf[selected_features]\n",
    "X = trainFDf.drop('label', axis=1)\n",
    "y = trainFDf['label']\n",
    "evalFDf = evalDf[selected_features]\n",
    "X_ev = evalFDf.drop('label', axis=1)\n",
    "y_ev = evalFDf['label']\n",
    "testFDf = testDf[selected_features]\n",
    "X_test = testFDf.drop('label', axis=1)\n",
    "y_test = testFDf['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf = SVR(kernel='rbf', C=10, verbose=2)\n",
    "svr_rbf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error on Test Data: 0.49396064959007535\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_test = svr_rbf.predict(X_test)\n",
    "\n",
    "# Calculate mean absolute error on test data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "print(\"Mean Absolute Error on Test Data:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHMmae_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ad81a87cda928bf31a314de06b951603fac3acce7ced8754b726311d2f5450"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
